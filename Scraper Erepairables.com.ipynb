{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "base_url=\"https://erepairables.com/salvage-cars-auction?vcondition%5B0%5D=damaged&pages=3183&start=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_file=1 #name of the picture in the local directory\n",
    "nb_pages=20 #nb of pages to parse. Each page contains 50 vehicles\n",
    "for i_page in range(0,nb_pages): #loop on pages\n",
    "    r=urllib2.urlopen(base_url+str(50*i_page)).read()\n",
    "    soup=BeautifulSoup(r)\n",
    "    links_cars=soup.find_all(\"a\",href=re.compile(\"on/cars/\")) #links to cars in this page\n",
    "    for car in links_cars: #loop on cars\n",
    "        car_tag=car.find(\"img\")\n",
    "        if car_tag!=None: #Some links are dead( return None)\n",
    "            car_src=car_tag[\"data-original\"] #get path to image\n",
    "            car_url=car_src[:-11]+\"shadowbox.jpg\" #change image path to get the higher quality\n",
    "            req=urllib2.Request(car_url)\n",
    "            try:\n",
    "                f=urllib2.urlopen(req)\n",
    "            except urllib2.HTTPError, e:\n",
    "                print(e.code)\n",
    "            except urllib2.URLError, e:\n",
    "                print(e.args)\n",
    "            local_file=open(\"./pics_erep/\"+str(index_file)+\".jpg\",\"w\")\n",
    "            local_file.write(f.read()) #Write locally\n",
    "            local_file.close\n",
    "            index_file=index_file+1 #Go for another car, the file number is incremented\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=50\">2</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=100\">3</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=150\">4</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=200\">5</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=250\">6</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=300\">7</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=350\">8</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=400\">9</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=450\">10</a>, <a href=\"/salvage-cars-auction?vcondition%5B0%5D=damaged&amp;pages=3183&amp;start=50\">Next <i class=\"uk-icon-double-angle-right\"></i></a>]\n"
     ]
    }
   ],
   "source": [
    "links_pages=soup.find_all(\"a\",href=re.compile(\"pages=\"))\n",
    "print(links_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
